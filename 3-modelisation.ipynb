{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea50dcf",
   "metadata": {},
   "source": [
    "This notebook contain the training using the library tabnet and the neural network with lightning_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a36ca21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24bdf426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X_train=torch.load('train_inputs')\n",
    "y_train=torch.load('train_outputs')\n",
    "\n",
    "X_val=torch.load('val_inputs')\n",
    "y_val=torch.load('val_outputs')\n",
    "\n",
    "X_test=torch.load('test_inputs')\n",
    "y_test=torch.load('test_outputs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7df44344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.4586, 6.5430, 6.5545,  ..., 6.3887, 6.3819, 7.0265])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0316c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Detach tensors to avoid DataLoader serialization issues\n",
    "X_train_detached = X_train.detach()\n",
    "y_train_detached = y_train.detach()\n",
    "X_test_detached = X_test.detach()\n",
    "y_test_detached = y_test.detach()\n",
    "X_val_detached = X_val.detach()\n",
    "y_val_detached = y_val.detach()\n",
    "\n",
    "# transformation to tensor dataset\n",
    "train_dataset = TensorDataset(X_train_detached, y_train_detached)\n",
    "test_dataset = TensorDataset(X_test_detached, y_test_detached)\n",
    "val_dataset = TensorDataset(X_val_detached, y_val_detached)\n",
    "\n",
    "# Dataloader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4,persistent_workers=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4,persistent_workers=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4,persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f882b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 44]),\n",
       " torch.Size([32]),\n",
       " tensor([[ 4.0000,  3.0000, -0.6466,  ...,  0.7807, -0.3420, -1.2116],\n",
       "         [ 5.0000,  2.0000, -0.8801,  ...,  0.3436,  0.2235, -0.0520],\n",
       "         [ 2.0000,  5.0000,  0.6191,  ..., -0.6025,  0.0446,  0.6243],\n",
       "         ...,\n",
       "         [ 4.0000,  4.0000, -0.1374,  ...,  0.4495,  0.7099, -0.1533],\n",
       "         [ 1.0000,  9.0000, -0.5541,  ..., -1.9610, -2.2232,  1.6628],\n",
       "         [ 2.0000,  5.0000,  0.3740,  ..., -0.7541,  0.3627, -0.9050]]),\n",
       " tensor([7.1826, 7.1765, 7.9275, 6.1079, 6.9360, 7.3812, 6.8740, 7.9122, 7.0419,\n",
       "         6.4387, 6.3850, 7.9384, 7.7129, 6.8277, 7.9026, 6.4268, 6.5961, 6.1645,\n",
       "         5.2566, 5.5081, 7.4772, 7.4965, 6.3104, 6.0463, 7.3193, 7.1586, 6.2153,\n",
       "         6.0908, 7.0439, 6.7717, 6.1346, 6.3696]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of iterating through the DataLoader\n",
    "ex_X, ex_y = next(iter(train_loader))\n",
    "ex_X.shape, ex_y.shape, ex_X, ex_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "541859d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\miniconda3\\envs\\d2l\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "# TabNet\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "# Initialize TabNetRegressor\n",
    "tab_net = TabNetRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4128de0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.699   | val_rmse: 0.09278 |  0:01:05s\n",
      "epoch 1  | loss: 0.01409 | val_rmse: 0.07995 |  0:02:09s\n",
      "epoch 2  | loss: 0.01049 | val_rmse: 0.07148 |  0:03:12s\n",
      "epoch 3  | loss: 0.00987 | val_rmse: 0.07771 |  0:04:17s\n",
      "epoch 4  | loss: 0.01024 | val_rmse: 0.07504 |  0:05:19s\n",
      "epoch 5  | loss: 0.00894 | val_rmse: 0.07347 |  0:06:22s\n",
      "\n",
      "Early stopping occurred at epoch 5 with best_epoch = 2 and best_val_rmse = 0.07148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\miniconda3\\envs\\d2l\\Lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "tab_net.fit(\n",
    "    X_train=X_train_detached.numpy(), y_train=y_train_detached.numpy().reshape(-1, 1),# reshape for single output\n",
    "    eval_set=[(X_val_detached.numpy(), y_val_detached.numpy().reshape(-1, 1))],# reshape for single output\n",
    "    eval_name=['val'],# name of the eval set\n",
    "    eval_metric=['rmse'],# metrics to be evaluated\n",
    "    max_epochs=10,# maximum number of epochs\n",
    "    patience=3,# early stopping patience\n",
    "    batch_size=1024, virtual_batch_size=128,# batch size and virtual batch size\n",
    "    num_workers=4,# number of workers for data loading\n",
    "    drop_last=False# whether to drop the last incomplete batch\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aed7b2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.005190330091863871, 0.057450033724308014, 0.9890401363372803)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "preds = tab_net.predict(X_test_detached.numpy())\n",
    "mean_squared_error(y_test_detached.numpy(), preds), mean_absolute_error(y_test_detached.numpy(), preds), r2_score(y_test_detached.numpy(), preds)\n",
    "# (0.002001001499593258, 0.03651253506541252, 0.9957746863365173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5abbad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network with Lightning\n",
    "from lightning import Trainer\n",
    "from torch import nn\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch import LightningModule\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchmetrics.regression import  MeanSquaredError, MeanAbsoluteError, R2Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "496c6617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if GPU is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f59e389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class LitModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        super(LitModel, self).__init__()\n",
    "        \n",
    "        # Define the layers of the neural network\n",
    "        self.layer1 = nn.Sequential(nn.Linear(X_train_detached.shape[1], 128), nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(nn.Linear(128, 64), nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(nn.Linear(64, 32), nn.ReLU())\n",
    "        self.layer4 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    # Training step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.view(-1, 1) # reshape for single output\n",
    "        logits = self(x)\n",
    "        loss = nn.functional.mse_loss(logits, y)\n",
    "        preds = logits.detach() # detach to avoid tracking in autograd\n",
    "        target = y.detach() # detach to avoid tracking in autograd\n",
    "\n",
    "        self.log(\"train_mse\",  MeanSquaredError().to(device)(preds, target), prog_bar=True, on_step=False, on_epoch=True) # log MSE\n",
    "        self.log(\"train_mae\",  MeanAbsoluteError().to(device)(preds, target), prog_bar=True, on_step=False, on_epoch=True) # log MAE\n",
    "        self.log(\"train_r2\",  R2Score().to(device)(preds, target), prog_bar=True, on_step=False, on_epoch=True) # log R2\n",
    "        return loss\n",
    "    \n",
    "    # Validation step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.view(-1, 1)\n",
    "        logits = self(x)\n",
    "        loss = nn.functional.mse_loss(logits, y)\n",
    "        preds = logits.detach()\n",
    "        target = y.detach()\n",
    "        self.log(\"val_mse\",  MeanSquaredError().to(device)(preds, target), prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_mae\",  MeanAbsoluteError().to(device)(preds, target), prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"val_r2\",  R2Score().to(device)(preds, target), prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "    \n",
    "    # Test step\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = y.view(-1, 1)\n",
    "        logits = self(x)\n",
    "        loss = nn.functional.mse_loss(logits, y)\n",
    "        preds = logits.detach()\n",
    "        target = y.detach()\n",
    "        self.log(\"test_mse\",  MeanSquaredError().to(device)(preds, target), prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"test_mae\",  MeanAbsoluteError().to(device)(preds, target), prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"test_r2\",  R2Score().to(device)(preds, target), prog_bar=True, on_step=False, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3) # Adam optimizer\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5) # Learning rate scheduler\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59da79d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = LitModel().to('cuda')\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    # devices=0,\n",
    "    max_epochs=10,\n",
    "    callbacks=[EarlyStopping(monitor=\"val_mse\", patience=3)], # early stopping callback\n",
    "    logger=TensorBoardLogger(\"logs/\") # log to TensorBoard\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd79a12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c065e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type       | Params | Mode \n",
      "----------------------------------------------\n",
      "0 | layer1 | Sequential | 5.8 K  | train\n",
      "1 | layer2 | Sequential | 8.3 K  | train\n",
      "2 | layer3 | Sequential | 2.1 K  | train\n",
      "3 | layer4 | Linear     | 33     | train\n",
      "----------------------------------------------\n",
      "16.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.1 K    Total params\n",
      "0.065     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5337be80bd64711808370937a6cee44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10208f2d3af149e79621adc4d5799683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7545fe82a9e498690da8dc5207de840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01a3fa04dc74bb7b0ccc4a36e66fc80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d84a1e9d664f24bd8bcf7d6b3adb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6570e927154236a459e0b8886416c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad4e67f074c49989a72640ceaae178d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c5c8b9cf31491d8d6dab024a5832da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67bb04870c24ff2acf0a1f73b08651e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dbd511aab44f248f8e81ef925e064f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f393f99a354bd3a47cce4855570322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18196f8996cd4e2dad967aa6dac67ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75e9850491f44d9bbfce28c1d5f71756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">        Test metric        </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_mae          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.03381076082587242    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">         test_mse          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">   0.0017126169987022877   </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          test_r2          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.9960328340530396     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_mae         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.03381076082587242   \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m        test_mse         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m  0.0017126169987022877  \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         test_r2         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.9960328340530396    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321c670e581e42a09e6a77459e7bb534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\">      Validate metric      </span>â”ƒ<span style=\"font-weight: bold\">       DataLoader 0        </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          val_mae          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.03360701724886894    </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          val_mse          </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">   0.0016909410478547215   </span>â”‚\n",
       "â”‚<span style=\"color: #008080; text-decoration-color: #008080\">          val_r2           </span>â”‚<span style=\"color: #800080; text-decoration-color: #800080\">    0.9960504174232483     </span>â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         val_mae         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.03360701724886894   \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         val_mse         \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m  0.0016909410478547215  \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â”‚\u001b[36m \u001b[0m\u001b[36m         val_r2          \u001b[0m\u001b[36m \u001b[0mâ”‚\u001b[35m \u001b[0m\u001b[35m   0.9960504174232483    \u001b[0m\u001b[35m \u001b[0mâ”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_mse': 0.0016909410478547215,\n",
       "  'val_mae': 0.03360701724886894,\n",
       "  'val_r2': 0.9960504174232483}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Test the model\n",
    "trainer.test(model, test_loader)\n",
    "\n",
    "# Validate the model\n",
    "trainer.validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1602fc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 4468), started 0:00:16 ago. (Use '!kill 4468' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bca861e7e7a4aa9c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bca861e7e7a4aa9c\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3a54727",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18183d4e6e9544a4b2d5cd9ffd35543b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = trainer.predict(model, ex_X.to(device))\n",
    "torch.tensor(p).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c8294f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3099002.2\n",
      "3564687.8\n",
      "3308868.8\n",
      "53907584.0\n",
      "838995.2\n",
      "9060325.0\n",
      "2265644.2\n",
      "1533385.4\n",
      "10537047.0\n",
      "8630332.0\n",
      "83543140.0\n",
      "33295760.0\n",
      "3975252.8\n",
      "291948.53\n",
      "601938.3\n",
      "14978192.0\n",
      "28004354.0\n",
      "120472990.0\n",
      "36804290.0\n",
      "5837697.0\n",
      "2177140.0\n",
      "30120740.0\n",
      "12189962.0\n",
      "3487022.2\n",
      "452428.56\n",
      "7284201.0\n",
      "4716561.0\n",
      "1287626.4\n",
      "11724625.0\n",
      "2129782.8\n",
      "216250.97\n",
      "294929340.0\n"
     ]
    }
   ],
   "source": [
    "for p in pred:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b10712af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fdc403db9514822bb6ec447997d131c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.099002e+06</td>\n",
       "      <td>2.875075e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.564688e+06</td>\n",
       "      <td>3.491493e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.308869e+06</td>\n",
       "      <td>3.585000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.390758e+07</td>\n",
       "      <td>5.761198e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.389952e+05</td>\n",
       "      <td>8.523132e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          preds        target\n",
       "0  3.099002e+06  2.875075e+06\n",
       "1  3.564688e+06  3.491493e+06\n",
       "2  3.308869e+06  3.585000e+06\n",
       "3  5.390758e+07  5.761198e+07\n",
       "4  8.389952e+05  8.523132e+05"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# prediction\n",
    "ex_X, ex_y = next(iter(test_loader))\n",
    "model.eval()\n",
    "preds = trainer.predict(model, ex_X.to(device))\n",
    "pred=np.power(10, torch.tensor(preds).cpu().detach().numpy().flatten()) \n",
    "y_true=np.power(10, ex_y.numpy().flatten())\n",
    "dict_preds = {'preds': [float(p) for p in pred], 'target': [float(t) for t in y_true]} # convert to dataframe\n",
    "pd.DataFrame(dict_preds).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce4373",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609076b",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4b800",
   "metadata": {},
   "source": [
    " we get very good result with tabnet(mean_squared_error: 0.002001001499593258, mean_absolute_error: 0.03651253506541252, r2_score: 0.9957746863365173) and neural network. In part EDA we see very bad correlation  columns (heatmap just see linear correlation) but good correlation between budget columns then it's normal to see very good result because the model will just use  these columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db9735",
   "metadata": {},
   "source": [
    "## little explication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffe47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Le fait quâ€™il y ait une faible corrÃ©lation linÃ©aire entre les colonnes (features) et la target nâ€™empÃªche pas forcÃ©ment un modÃ¨le (surtout un rÃ©seau de neurones) de bien performer :\n",
    "\n",
    "1. CorrÃ©lation â‰  Relation rÃ©elle\n",
    "\n",
    "La corrÃ©lation simple (Pearson) ne capture que les relations linÃ©aires.\n",
    "\n",
    "Si la relation est non linÃ©aire (par exemple quadratique, logarithmique, interaction entre variablesâ€¦), la corrÃ©lation peut Ãªtre proche de 0, mais le modÃ¨le arrive quand mÃªme Ã  exploiter cette structure.\n",
    "\n",
    "Exemple :\n",
    "\n",
    "ğ‘¦=ğ‘¥2\n",
    "\n",
    "Si ğ‘¥ est centrÃ© autour de 0, la corrÃ©lation entre ğ‘¥ et ğ‘¦ est trÃ¨s faible voire nulleâ€¦ mais une rÃ©gression non linÃ©aire apprend facilement la relation.\n",
    "\n",
    "2. Puissance des modÃ¨les complexes\n",
    "\n",
    "Les rÃ©seaux de neurones (mÃªme petits) capturent des interactions complexes entre variables, lÃ  oÃ¹ un calcul de corrÃ©lation simple passe Ã  cÃ´tÃ©.\n",
    "\n",
    "Cela explique pourquoi tu peux avoir RÂ² ou accuracy Ã©levÃ©s malgrÃ© des colonnes avec trÃ¨s peu de corrÃ©lation.\n",
    "\n",
    "3. MultivariÃ© â‰  univariÃ©\n",
    "\n",
    "Chaque colonne peut avoir une corrÃ©lation faible avec la target.\n",
    "\n",
    "Mais plusieurs colonnes combinÃ©es peuvent contenir une information forte.\n",
    "\n",
    "Câ€™est justement le rÃ´le du modÃ¨le dâ€™assembler ces signaux faibles.\n",
    "\n",
    "âœ… En pratique :\n",
    "\n",
    "Une faible corrÃ©lation nâ€™est pas un problÃ¨me si ton modÃ¨le apprend bien (bonne loss, bon RÂ², pas de surapprentissage)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531da18",
   "metadata": {},
   "source": [
    "The fact that there is a low linear correlation between the columns (features) and the Target does not necessarily prevent a model (especially a network of neurons) from performing well:\n",
    "\n",
    "1. Correlation â‰  real relationship\n",
    "\n",
    "Simple correlation (Pearson) only captures linear relationships.\n",
    "\n",
    "If the relationship is non -linear (for example quadratic, logarithmic, interaction between variables, etc.), the correlation can be close to 0, but the model still manages to exploit this structure.\n",
    "\n",
    "Example :\n",
    "\n",
    "ğ‘¦ = ğ‘¥2\n",
    "\n",
    "If ğ‘¥ is centered around 0, the correlation between ğ‘¥ and ğ‘¦ is very low or even zero ... but a non -linear regression easily learns the relationship.\n",
    "\n",
    "2. Power of complex models\n",
    "\n",
    "The neural networks (even small) capture complex interactions between variables, where a simple correlation calculation passes next.\n",
    "\n",
    "This explains why you can have rÂ² or high battery despite columns with very little correlation.\n",
    "\n",
    "3. MultivariÃ© â‰  univariÃ©\n",
    "\n",
    "Each column can have a weak correlation with the Target.\n",
    "\n",
    "But several combined columns may contain strong information.\n",
    "\n",
    "This is precisely the role of the model to assemble these weak signals.\n",
    "\n",
    "âœ… In practice:\n",
    "\n",
    "A low correlation is not a problem if your model learns well (good loss, good RÂ², no over -appreation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
